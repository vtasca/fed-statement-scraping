# inspired by https://github.com/simonw/ca-fires-history/blob/main/.github/workflows/scrape.yml

name: Scrape latest statement

on:
  push:
  workflow_dispatch:
  schedule:
  - cron: '0 8 * * 1'

permissions:
  contents: write

jobs:
  scheduled:
    runs-on: ubuntu-latest
    steps:
    - name: Check out this repo
      uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        cache: 'pip' # caching pip dependencies
    - run: pip install -r requirements.txt
    - name: Fetch latest data
      run: python scrape.py
    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" || exit 0
        git push
    - name: Push data to Hugging Face
      run: |-
        git lfs install
        mkdir -p hf_repo
        cp communications.csv hf_repo/
        cd hf_repo
        git init
        git config user.name "Automated (GitHub)"
        git config user.email "actions@users.noreply.github.com"
        git lfs track "communications.csv"
        git add .gitattributes communications.csv
        git commit -m "Update data: $(date -u)"
        git branch -M main
        git remote add origin https://user:$HF_TOKEN@huggingface.co/datasets/vtasca/fomc-statements-minutes
        git push origin main --force
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
