name: Scrape and Publish Latest Statement

on:
  push:
  workflow_dispatch:
  schedule:
    - cron: '0 8 * * 1'  # every Monday 8:00 UTC

permissions:
  contents: write

jobs:
  scheduled:
    runs-on: ubuntu-latest

    steps:
    - name: Check out this repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Fetch latest data
      run: python scrape.py

    # Commit changes to GitHub repo
    - name: Commit and push if changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" || echo "No changes to commit"
        git push

    # Install Git LFS
    - name: Install Git LFS
      run: |
        sudo apt-get update
        sudo apt-get install -y git-lfs
        git lfs install

    # Push CSV to Hugging Face (preserve history)
    - name: Push data to Hugging Face
      if: ${{ secrets.HF_TOKEN != '' }}
      run: |
        # Clone HF dataset repo
        git clone https://user:${HF_TOKEN}@huggingface.co/datasets/vtasca/fomc-statements-minutes hf_repo
        cd hf_repo

        # Track CSV with LFS (only needed first time)
        git lfs track "communications.csv"
        git add .gitattributes || true

        # Copy new CSV and commit
        cp ../communications.csv .
        git add communications.csv
        git commit -m "Update data: $(date -u)" || echo "No changes to commit"

        # Push to HF
        git push origin main
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
